{"cells": [{"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["import os\n", "import json\n", "from dotenv import load_dotenv\n", "from typing import Dict, Any\n", "from datetime import datetime\n", "\n", "import requests\n", "import pandas as pd\n", "import yfinance as yf\n", "\n", "load_dotenv()\n", "API_KEY = os.getenv(\"VANTAGE_API_KEY\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data Fetching and Caching"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["class APIRateLimitError(Exception):\n", "    \"\"\"Custom exception raised when the API rate limit is exceeded.\"\"\"\n", "    pass\n", "\n", "def fetch_income_statement(symbol: str, api_key: str, folder: str = 'data') -> dict:\n", "    file_path = os.path.join(folder, f'{symbol}_income_statement.json')\n", "    if os.path.exists(file_path):\n", "        with open(file_path, 'r') as f:\n", "            return json.load(f)\n", "    url = f'https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol={symbol}&apikey={api_key}'\n", "    response = requests.get(url)\n", "    data = response.json()\n", "    if \"Information\" in data and \"rate limit\" in data[\"Information\"].lower():\n", "        raise APIRateLimitError(data[\"Information\"])\n", "    os.makedirs(folder, exist_ok=True)\n", "    with open(file_path, 'w') as f:\n", "        json.dump(data, f)\n", "    return data\n", "\n", "\n", "def fetch_balance_sheet(symbol: str, api_key: str, folder: str = 'data') -> dict:\n", "    file_path = os.path.join(folder, f'{symbol}_balance_sheet.json')\n", "    if os.path.exists(file_path):\n", "        with open(file_path, 'r') as f:\n", "            return json.load(f)\n", "    url = f'https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol={symbol}&apikey={api_key}'\n", "    response = requests.get(url)\n", "    data = response.json()\n", "    if \"Information\" in data and \"rate limit\" in data[\"Information\"].lower():\n", "        raise APIRateLimitError(data[\"Information\"])\n", "    os.makedirs(folder, exist_ok=True)\n", "    with open(file_path, 'w') as f:\n", "        json.dump(data, f)\n", "    return data\n", "\n", "\n", "def fetch_cash_flow(symbol: str, api_key: str, folder: str = 'data') -> dict:\n", "    file_path = os.path.join(folder, f'{symbol}_cash_flow.json')\n", "    if os.path.exists(file_path):\n", "        with open(file_path, 'r') as f:\n", "            return json.load(f)\n", "    url = f'https://www.alphavantage.co/query?function=CASH_FLOW&symbol={symbol}&apikey={api_key}'\n", "    response = requests.get(url)\n", "    data = response.json()\n", "    if \"Information\" in data and \"rate limit\" in data[\"Information\"].lower():\n", "        raise APIRateLimitError(data[\"Information\"])\n", "    os.makedirs(folder, exist_ok=True)\n", "    with open(file_path, 'w') as f:\n", "        json.dump(data, f)\n", "    return data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Merge Reports"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["def convert_columns_to_numeric(df):\n", "    \"\"\"\n", "    Convert necessary columns to numeric within a DataFrame.\n", "    \"\"\"\n", "    numeric_cols = [\n", "        'netIncome', 'totalRevenue', 'operatingCashflow', 'capitalExpenditures',\n", "        'cashAndCashEquivalentsAtCarryingValue', 'totalAssets',\n", "        'totalCurrentLiabilities', 'currentDebt', 'cashAndShortTermInvestments',\n", "        'longTermDebt', 'commonStockSharesOutstanding'\n", "    ]\n", "    for col in numeric_cols:\n", "        if col in df.columns:\n", "            df[col] = pd.to_numeric(df[col], errors='coerce')\n", "\n", "\n", "def merge_reports_df(income_statement: dict,\n", "                     balance_sheet: dict,\n", "                     cash_flow: dict) -> Dict[str, Any]:\n", "    \"\"\"\n", "    Merge annual and quarterly reports from three API responses into two DataFrames.\n", "    Return a dict with 'symbol', 'annual' DataFrame, and 'quarterly' DataFrame.\n", "    \"\"\"\n", "    # --- Annual Reports ---\n", "    annual_income = pd.DataFrame(income_statement.get('annualReports', []))\n", "    annual_balance = pd.DataFrame(balance_sheet.get('annualReports', []))\n", "    annual_cash = pd.DataFrame(cash_flow.get('annualReports', []))\n", "\n", "    # Drop unwanted columns to avoid collisions in merges\n", "    annual_balance.drop(columns=['reportedCurrency'], errors='ignore', inplace=True)\n", "    annual_cash.drop(columns=['reportedCurrency', 'netIncome'], errors='ignore', inplace=True)\n", "\n", "    # Convert 'fiscalDateEnding' to datetime and sort\n", "    for df in (annual_income, annual_balance, annual_cash):\n", "        if 'fiscalDateEnding' in df.columns:\n", "            df['fiscalDateEnding'] = pd.to_datetime(df['fiscalDateEnding'])\n", "            df.sort_values('fiscalDateEnding', inplace=True)\n", "            df.reset_index(drop=True, inplace=True)\n", "\n", "    # Merge annual data\n", "    annual_df = pd.merge(annual_income, annual_balance, on='fiscalDateEnding', how='outer')\n", "    annual_df = pd.merge(annual_df, annual_cash, on='fiscalDateEnding', how='outer')\n", "    convert_columns_to_numeric(annual_df)\n", "\n", "    # --- Quarterly Reports ---\n", "    quarterly_income = pd.DataFrame(income_statement.get('quarterlyReports', []))\n", "    quarterly_balance = pd.DataFrame(balance_sheet.get('quarterlyReports', []))\n", "    quarterly_cash = pd.DataFrame(cash_flow.get('quarterlyReports', []))\n", "\n", "    # Drop unwanted columns\n", "    quarterly_balance.drop(columns=['reportedCurrency'], errors='ignore', inplace=True)\n", "    quarterly_cash.drop(columns=['reportedCurrency', 'netIncome'], errors='ignore', inplace=True)\n", "\n", "    for df in (quarterly_income, quarterly_balance, quarterly_cash):\n", "        if 'fiscalDateEnding' in df.columns:\n", "            df['fiscalDateEnding'] = pd.to_datetime(df['fiscalDateEnding'])\n", "            df.sort_values('fiscalDateEnding', inplace=True)\n", "            df.reset_index(drop=True, inplace=True)\n", "\n", "    # Merge quarterly data\n", "    quarterly_df = pd.merge(quarterly_income, quarterly_balance, on='fiscalDateEnding', how='outer')\n", "    quarterly_df = pd.merge(quarterly_df, quarterly_cash, on='fiscalDateEnding', how='outer')\n", "    convert_columns_to_numeric(quarterly_df)\n", "\n", "    return {\n", "        'symbol': income_statement.get('symbol', 'N/A'),\n", "        'annual': annual_df,\n", "        'quarterly': quarterly_df\n", "    }"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Price Retrieval"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["def get_yearly_close_prices(ticker_symbol: str,\n", "                            start_year: int,\n", "                            end_year: int) -> pd.DataFrame:\n", "    \"\"\"\n", "    Retrieve and return a DataFrame with columns:\n", "        'year' and 'close' (the last close price of that year).\n", "    \"\"\"\n", "    start_date = f\"{start_year}-01-01\"\n", "    end_date = f\"{end_year}-12-31\"\n", "\n", "    ticker = yf.Ticker(ticker_symbol)\n", "    hist = ticker.history(start=start_date, end=end_date)\n", "\n", "    if hist.empty:\n", "        return pd.DataFrame(columns=['year', 'close'])\n", "\n", "    if not isinstance(hist.index, pd.DatetimeIndex):\n", "        hist.index = pd.to_datetime(hist.index)\n", "\n", "    # Resample to get the last closing price of each year\n", "    yearly = hist['Close'].resample('YE').last().dropna()\n", "\n", "    # Convert to a DataFrame with columns: year, close\n", "    df_price = yearly.reset_index()\n", "    df_price['year'] = df_price['Date'].dt.year\n", "    df_price.rename(columns={'Close': 'close'}, inplace=True)\n", "    return df_price[['year', 'close']]\n", "\n", "\n", "def get_latest_price(ticker_symbol: str) -> float:\n", "    \"\"\"\n", "    Get the latest market price (attempt from 'regularMarketPrice'\n", "    or fallback to 'previousClose').\n", "    \"\"\"\n", "    ticker = yf.Ticker(ticker_symbol)\n", "    latest_price = ticker.info.get('previousClose')\n", "    return float(latest_price) if latest_price else None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Analysis"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": ["def safe_float(value):\n", "    \"\"\"Return a float when possible; otherwise None.\"\"\"\n", "    if value is None:\n", "        return None\n", "    try:\n", "        if pd.isna(value):\n", "            return None\n", "    except TypeError:\n", "        pass\n", "    try:\n", "        return float(value)\n", "    except (TypeError, ValueError):\n", "        return None\n", "\n", "\n", "def safe_divide(numerator, denominator):\n", "    \"\"\"Defensive division that ignores None/NaN/zero denominators.\"\"\"\n", "    if numerator is None or denominator is None:\n", "        return None\n", "    try:\n", "        numerator = float(numerator)\n", "        denominator = float(denominator)\n", "    except (TypeError, ValueError):\n", "        return None\n", "    if denominator == 0 or pd.isna(numerator) or pd.isna(denominator):\n", "        return None\n", "    return numerator / denominator\n", "\n", "\n", "def series_mean(series: pd.Series) -> float | None:\n", "    if series is None or series.empty:\n", "        return None\n", "    return safe_float(series.mean())\n", "\n", "\n", "WINDOW_PERIODS = (1, 2, 5, 10)\n", "\n", "def windowed_means(series: pd.Series, windows: tuple[int, ...] = WINDOW_PERIODS) -> dict[str, float | None]:\n", "    \"\"\"Return trailing means for the requested window sizes.\"\"\"\n", "    results: dict[str, float | None] = {}\n", "    if series is None:\n", "        return {f\"{years}Y\": None for years in windows}\n", "    cleaned = series.dropna()\n", "    for years in windows:\n", "        label = f\"{years}Y\"\n", "        if len(cleaned) >= years:\n", "            window_slice = cleaned.tail(years)\n", "            results[label] = safe_float(window_slice.mean())\n", "        else:\n", "            results[label] = None\n", "    return results\n", "\n", "\n", "def prepare_annual_frame(raw: pd.DataFrame) -> pd.DataFrame:\n", "    \"\"\"Return annual reports with derived FCF and fiscal year.\"\"\"\n", "    df = raw.copy()\n", "    if df.empty:\n", "        return df\n", "    df['fcf'] = df['operatingCashflow'] - df['capitalExpenditures']\n", "    df['year'] = df['fiscalDateEnding'].dt.year\n", "    return df\n", "\n", "\n", "def prepare_quarterly_frame(raw: pd.DataFrame) -> pd.DataFrame:\n", "    \"\"\"Return quarterly reports with TTM aggregates and share data.\"\"\"\n", "    df = raw.copy()\n", "    if df.empty:\n", "        return df\n", "    df['fcf'] = df['operatingCashflow'] - df['capitalExpenditures']\n", "    df['ttm_fcf'] = df['fcf'].rolling(4).sum()\n", "    df['ttm_net_income'] = df['netIncome'].rolling(4).sum()\n", "    df['shares'] = df['commonStockSharesOutstanding'].ffill().bfill()\n", "    df['ttm_eps'] = df.apply(lambda row: safe_divide(row['ttm_net_income'], row['shares']), axis=1)\n", "    df['ttm_fcf_ps'] = df.apply(lambda row: safe_divide(row['ttm_fcf'], row['shares']), axis=1)\n", "    return df\n", "\n", "\n", "def extract_ttm_metrics(quarterly_df: pd.DataFrame) -> dict[str, Any]:\n", "    \"\"\"Pull the latest TTM metrics out of the enriched quarterly frame.\"\"\"\n", "    if quarterly_df.empty:\n", "        return {\n", "            'latest_quarter_eps': None,\n", "            'ttm_eps': None,\n", "            'ttm_fcf_ps': None,\n", "            'fiscal_date_ending': None,\n", "        }\n", "    latest = quarterly_df.iloc[-1]\n", "    return {\n", "        'latest_quarter_eps': safe_divide(latest['netIncome'], latest['shares']),\n", "        'ttm_eps': safe_float(latest.get('ttm_eps')),\n", "        'ttm_fcf_ps': safe_float(latest.get('ttm_fcf_ps')),\n", "        'fiscal_date_ending': latest['fiscalDateEnding'].strftime('%Y-%m-%d') if pd.notnull(latest['fiscalDateEnding']) else None,\n", "    }\n", "\n", "\n", "def compute_growth_metrics(annual_df: pd.DataFrame, num_periods: int) -> tuple[dict[str, Any], pd.DataFrame, dict[str, dict[str, float | None]]]:\n", "    \"\"\"Compute revenue/FCF/share growth plus leverage and margin details.\"\"\"\n", "    df = annual_df.copy()\n", "    if df.empty:\n", "        empty_metrics = {\n", "            'avg_turnover_growth': None,\n", "            'avg_FCF_growth': None,\n", "            'avg_ROCE_using_FCF': None,\n", "            'latest_net_debt_to_FCF': None,\n", "            'avg_stock_increase': None,\n", "            'avg_FCF_margin': None,\n", "        }\n", "        return empty_metrics, df, {\n", "            'revenue_growth': windowed_means(None),\n", "            'fcf_growth': windowed_means(None),\n", "            'roce_fcf': windowed_means(None),\n", "            'shares_growth': windowed_means(None),\n", "        }\n", "\n", "    df['revenue_growth'] = df['totalRevenue'].pct_change()\n", "    df['fcf_growth'] = df['fcf'].pct_change()\n", "    df['shares_growth'] = df['commonStockSharesOutstanding'].pct_change()\n", "\n", "    df['capital_employed'] = df['totalAssets'] - df['totalCurrentLiabilities']\n", "\n", "    cash_series = df.get('cashAndShortTermInvestments')\n", "    if cash_series is None or cash_series.empty:\n", "        cash_series = df.get('cashAndCashEquivalentsAtCarryingValue')\n", "    df['cash'] = cash_series.fillna(0) if cash_series is not None else 0.0\n", "\n", "    for debt_col in ('currentDebt', 'longTermDebt'):\n", "        if debt_col in df:\n", "            df[debt_col] = df[debt_col].fillna(0)\n", "        else:\n", "            df[debt_col] = 0.0\n", "\n", "    df['debt'] = df['currentDebt'] + df['longTermDebt']\n", "    df['net_debt'] = df['debt'] - df['cash']\n", "\n", "    df['roce_fcf'] = df.apply(lambda row: safe_divide(row['fcf'], row['capital_employed']), axis=1)\n", "    df['net_debt_to_fcf'] = df.apply(lambda row: safe_divide(row['net_debt'], row['fcf']), axis=1)\n", "    df['fcf_margin'] = df.apply(lambda row: safe_divide(row['fcf'], row['totalRevenue']), axis=1)\n", "\n", "    recent_subset = df.tail(num_periods)\n", "    averages = {\n", "        'avg_turnover_growth': series_mean(recent_subset['revenue_growth']),\n", "        'avg_FCF_growth': series_mean(recent_subset['fcf_growth']),\n", "        'avg_ROCE_using_FCF': series_mean(recent_subset['roce_fcf']),\n", "        'avg_stock_increase': series_mean(recent_subset['shares_growth']),\n", "        'avg_FCF_margin': series_mean(recent_subset['fcf_margin']),\n", "    }\n", "\n", "    net_debt_series = df['net_debt_to_fcf'].dropna()\n", "    averages['latest_net_debt_to_FCF'] = safe_float(net_debt_series.iloc[-1]) if not net_debt_series.empty else None\n", "\n", "    trend_windows = {\n", "        'revenue_growth': windowed_means(df['revenue_growth']),\n", "        'fcf_growth': windowed_means(df['fcf_growth']),\n", "        'roce_fcf': windowed_means(df['roce_fcf']),\n", "        'shares_growth': windowed_means(df['shares_growth']),\n", "    }\n", "\n", "    return averages, df, trend_windows\n", "\n", "\n", "def build_historical_records(df: pd.DataFrame) -> list[dict[str, Any]]:\n", "    \"\"\"Project annual history into serialisable dictionaries.\"\"\"\n", "    if df.empty:\n", "        return []\n", "    records: list[dict[str, Any]] = []\n", "    for _, row in df[['year', 'totalRevenue', 'fcf', 'roce_fcf', 'commonStockSharesOutstanding', 'fcf_margin']].iterrows():\n", "        records.append({\n", "            'year': int(row['year']) if pd.notnull(row['year']) else None,\n", "            'turnover': safe_float(row['totalRevenue']),\n", "            'FCF': safe_float(row['fcf']),\n", "            'ROCE_using_FCF': safe_float(row['roce_fcf']),\n", "            'shares': safe_float(row['commonStockSharesOutstanding']),\n", "            'FCF_margin': safe_float(row['fcf_margin']),\n", "        })\n", "    return records\n", "\n", "\n", "def compute_price_ratios(symbol: str,\n", "                         annual_df: pd.DataFrame,\n", "                         ttm_metrics: dict[str, Any],\n", "                         num_periods: int) -> dict[str, Any]:\n", "    \"\"\"Compute valuation ratios from annual figures and market prices.\"\"\"\n", "    year_values = annual_df['year'].dropna() if 'year' in annual_df else pd.Series(dtype=int)\n", "    end_year = int(year_values.max()) if not year_values.empty else datetime.today().year - 1\n", "    start_year = end_year - 10\n", "\n", "    df_price = get_yearly_close_prices(symbol, start_year, end_year)\n", "    annual_price_df = pd.merge(annual_df, df_price, on='year', how='left')\n", "\n", "    annual_price_df['eps'] = annual_price_df.apply(\n", "        lambda row: safe_divide(row['netIncome'], row['commonStockSharesOutstanding']),\n", "        axis=1,\n", "    )\n", "    annual_price_df['p_e'] = annual_price_df.apply(\n", "        lambda row: safe_divide(row['close'], row['eps']),\n", "        axis=1,\n", "    )\n", "    annual_price_df['fcf_per_share'] = annual_price_df.apply(\n", "        lambda row: safe_divide(row['fcf'], row['commonStockSharesOutstanding']),\n", "        axis=1,\n", "    )\n", "    annual_price_df['p_fcf'] = annual_price_df.apply(\n", "        lambda row: safe_divide(row['close'], row['fcf_per_share']),\n", "        axis=1,\n", "    )\n", "\n", "    valid_pe = annual_price_df['p_e'].dropna()\n", "    valid_pfcf = annual_price_df['p_fcf'].dropna()\n", "\n", "    average_pe_5y = series_mean(valid_pe.tail(5)) if len(valid_pe) >= 5 else None\n", "    average_pe_10y = series_mean(valid_pe.tail(10)) if len(valid_pe) >= 10 else None\n", "    average_pfcf_5y = series_mean(valid_pfcf.tail(5)) if len(valid_pfcf) >= 5 else None\n", "    average_pfcf_10y = series_mean(valid_pfcf.tail(10)) if len(valid_pfcf) >= 10 else None\n", "\n", "    average_per = series_mean(valid_pe.tail(num_periods)) if not valid_pe.empty else None\n", "\n", "    latest_price = safe_float(get_latest_price(symbol))\n", "    ttm_fcf_ps = safe_float(ttm_metrics.get('ttm_fcf_ps'))\n", "    ttm_eps = safe_float(ttm_metrics.get('ttm_eps'))\n", "    latest_quarter_eps = safe_float(ttm_metrics.get('latest_quarter_eps'))\n", "\n", "    ttm_pfcf = safe_divide(latest_price, ttm_fcf_ps) if latest_price is not None else None\n", "    ttm_per = safe_divide(latest_price, ttm_eps) if latest_price is not None else None\n", "    latest_per = safe_divide(latest_price, latest_quarter_eps * 4) if (latest_price is not None and latest_quarter_eps is not None) else None\n", "\n", "    return {\n", "        'latest_price': latest_price,\n", "        'ttm_per': ttm_per,\n", "        'latest_per': latest_per,\n", "        'average_per': average_per,\n", "        'average_pe_5y': average_pe_5y,\n", "        'average_pe_10y': average_pe_10y,\n", "        'ttm_pfcf': ttm_pfcf,\n", "        'average_pfcf_5y': average_pfcf_5y,\n", "        'average_pfcf_10y': average_pfcf_10y,\n", "    }\n", "\n", "\n", "def build_dcf_inputs(annual_df: pd.DataFrame, ttm_fcf_ps: float | None) -> dict[str, Any]:\n", "    \"\"\"Extract the latest balance sheet inputs for the DCF form.\"\"\"\n", "    if annual_df.empty:\n", "        return {\n", "            'fcf_ps': safe_float(ttm_fcf_ps),\n", "            'cash': None,\n", "            'debt': None,\n", "            'shares': None,\n", "        }\n", "\n", "    latest = annual_df.iloc[-1]\n", "    cash_val = latest.get('cashAndShortTermInvestments')\n", "    if not cash_val:\n", "        cash_val = latest.get('cashAndCashEquivalentsAtCarryingValue')\n", "\n", "    current_debt = latest.get('currentDebt') or 0\n", "    long_term_debt = latest.get('longTermDebt') or 0\n", "\n", "    return {\n", "        'fcf_ps': safe_float(ttm_fcf_ps),\n", "        'cash': safe_float(cash_val),\n", "        'debt': safe_float(current_debt + long_term_debt),\n", "        'shares': safe_float(latest.get('commonStockSharesOutstanding')),\n", "    }\n", "\n", "\n", "def analyze_dataframes(symbol: str,\n", "                       annual_df: pd.DataFrame,\n", "                       quarterly_df: pd.DataFrame,\n", "                       num_periods: int = 5) -> Dict[str, Any]:\n", "    \"\"\"High-level orchestrator that combines all computations.\"\"\"\n", "\n", "    annual_clean = prepare_annual_frame(annual_df)\n", "    quarterly_clean = prepare_quarterly_frame(quarterly_df)\n", "\n", "    ttm_metrics = extract_ttm_metrics(quarterly_clean)\n", "\n", "    growth_metrics, growth_frame, trend_windows = compute_growth_metrics(annual_clean, num_periods)\n", "    historical_metrics = build_historical_records(growth_frame)\n", "\n", "    price_metrics = compute_price_ratios(symbol, annual_clean, ttm_metrics, num_periods)\n", "    dcf_inputs = build_dcf_inputs(annual_clean, ttm_metrics.get('ttm_fcf_ps'))\n", "\n", "    results = {\n", "        **growth_metrics,\n", "        'historical_metrics': historical_metrics,\n", "        **price_metrics,\n", "        'trend_windows': trend_windows,\n", "        'latest_quarterly_eps': ttm_metrics.get('latest_quarter_eps'),\n", "        'ttm_eps': ttm_metrics.get('ttm_eps'),\n", "        'ttm_fcf_ps': ttm_metrics.get('ttm_fcf_ps'),\n", "        'fiscal_date_ending': ttm_metrics.get('fiscal_date_ending'),\n", "        'dcf_inputs': dcf_inputs,\n", "        'analysis_date': datetime.now().strftime('%Y-%m-%d'),\n", "        'symbol': symbol,\n", "    }\n", "\n", "    return results\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## High-Level Function"]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": ["def analyze_stock(ticker: str, api_key: str, num_periods: int = 5) -> Dict[str, Any]:\n", "    \"\"\"\n", "    Fetch raw data, merge, run the all-in-DataFrame analysis, and return\n", "    a dictionary of results (no printing or saving).\n", "    \"\"\"\n", "    # Fetch data\n", "    income_statement = fetch_income_statement(ticker, api_key)\n", "    balance_sheet_data = fetch_balance_sheet(ticker, api_key)\n", "    cash_flow_data = fetch_cash_flow(ticker, api_key)\n", "\n", "    # Merge into DataFrames\n", "    merged_data = merge_reports_df(income_statement, balance_sheet_data, cash_flow_data)\n", "    annual_df = merged_data['annual']\n", "    quarterly_df = merged_data['quarterly']\n", "    symbol = merged_data.get('symbol', ticker)\n", "\n", "    # Perform the big analysis\n", "    results = analyze_dataframes(symbol, annual_df, quarterly_df, num_periods=num_periods)\n", "    return results"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Usage"]}, {"cell_type": "code", "execution_count": 23, "metadata": {"tags": ["parameters"]}, "outputs": [], "source": ["ticker = 'ASML'"]}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "    \"avg_turnover_growth\": 0.19576410689450405,\n", "    \"avg_FCF_growth\": 0.6301749756447773,\n", "    \"avg_ROCE_using_FCF\": 0.3059943567695744,\n", "    \"avg_stock_increase\": -0.013594138702447944,\n", "    \"avg_FCF_margin\": 0.31533086770520197,\n", "    \"latest_net_debt_to_FCF\": -0.9955599516430377,\n", "    \"historical_metrics\": [\n", "        {\n", "            \"year\": 2005,\n", "            \"turnover\": 2527046847.0,\n", "            \"FCF\": 638348174.17,\n", "            \"ROCE_using_FCF\": 0.2734684339819501,\n", "            \"shares\": 371639006.0,\n", "            \"FCF_margin\": 0.252606387146253\n", "        },\n", "        {\n", "            \"year\": 2006,\n", "            \"turnover\": 3581773383.0,\n", "            \"FCF\": 406768148.90999997,\n", "            \"ROCE_using_FCF\": 0.1468678621242473,\n", "            \"shares\": 388066910.0,\n", "            \"FCF_margin\": 0.11356613202851532\n", "        },\n", "        {\n", "            \"year\": 2007,\n", "            \"turnover\": 3774123817.0,\n", "            \"FCF\": 491916937.08000004,\n", "            \"ROCE_using_FCF\": 0.17775817020295248,\n", "            \"shares\": 373945110.0,\n", "            \"FCF_margin\": 0.13033937436398632\n", "        },\n", "        {\n", "            \"year\": 2008,\n", "            \"turnover\": 2953678000.0,\n", "            \"FCF\": 20990613.120000005,\n", "            \"ROCE_using_FCF\": 0.007144519732420332,\n", "            \"shares\": 334337850.0,\n", "            \"FCF_margin\": 0.0071066017081076556\n", "        },\n", "        {\n", "            \"year\": 2009,\n", "            \"turnover\": 1596063000.0,\n", "            \"FCF\": -7195000.0,\n", "            \"ROCE_using_FCF\": -0.0026813727883332893,\n", "            \"shares\": 333113550.0,\n", "            \"FCF_margin\": -0.0045079674173262585\n", "        },\n", "        {\n", "            \"year\": 2010,\n", "            \"turnover\": 4507938000.0,\n", "            \"FCF\": 811300000.0,\n", "            \"ROCE_using_FCF\": 0.2015852507081449,\n", "            \"shares\": 438974000.0,\n", "            \"FCF_margin\": 0.17997141930523444\n", "        },\n", "        {\n", "            \"year\": 2011,\n", "            \"turnover\": 5651035000.0,\n", "            \"FCF\": 1769531000.0,\n", "            \"ROCE_using_FCF\": 0.3322229389959627,\n", "            \"shares\": 429053000.0,\n", "            \"FCF_margin\": 0.3131339657248628\n", "        },\n", "        {\n", "            \"year\": 2012,\n", "            \"turnover\": 4731555000.0,\n", "            \"FCF\": 524000000.0,\n", "            \"ROCE_using_FCF\": 0.09841854175275158,\n", "            \"shares\": 426986000.0,\n", "            \"FCF_margin\": 0.11074583302952201\n", "        },\n", "        {\n", "            \"year\": 2013,\n", "            \"turnover\": 5245326000.0,\n", "            \"FCF\": 842479000.0,\n", "            \"ROCE_using_FCF\": 0.09021858392807691,\n", "            \"shares\": 433446000.0,\n", "            \"FCF_margin\": 0.16061518387989612\n", "        },\n", "        {\n", "            \"year\": 2014,\n", "            \"turnover\": 5856277000.0,\n", "            \"FCF\": 667946000.0,\n", "            \"ROCE_using_FCF\": 0.0656105397119268,\n", "            \"shares\": 439693000.0,\n", "            \"FCF_margin\": 0.11405642185299637\n", "        },\n", "        {\n", "            \"year\": 2015,\n", "            \"turnover\": 6287400000.0,\n", "            \"FCF\": 1652600000.0,\n", "            \"ROCE_using_FCF\": 0.1622136280649404,\n", "            \"shares\": 433021390.0,\n", "            \"FCF_margin\": 0.2628431466106817\n", "        },\n", "        {\n", "            \"year\": 2016,\n", "            \"turnover\": 6875100000.0,\n", "            \"FCF\": 1341200000.0,\n", "            \"ROCE_using_FCF\": 0.09631390347066131,\n", "            \"shares\": 427967032.0,\n", "            \"FCF_margin\": 0.19508079882474436\n", "        },\n", "        {\n", "            \"year\": 2017,\n", "            \"turnover\": 8962700000.0,\n", "            \"FCF\": 1440600000.0,\n", "            \"ROCE_using_FCF\": 0.0969807129152782,\n", "            \"shares\": 431600000.0,\n", "            \"FCF_margin\": 0.16073281488837068\n", "        },\n", "        {\n", "            \"year\": 2018,\n", "            \"turnover\": 10944000000.0,\n", "            \"FCF\": 2463200000.0,\n", "            \"ROCE_using_FCF\": 0.13773205099530306,\n", "            \"shares\": 426400000.0,\n", "            \"FCF_margin\": 0.22507309941520467\n", "        },\n", "        {\n", "            \"year\": 2019,\n", "            \"turnover\": 11820000000.0,\n", "            \"FCF\": 2509800000.0,\n", "            \"ROCE_using_FCF\": 0.12976578253451218,\n", "            \"shares\": 421600000.0,\n", "            \"FCF_margin\": 0.21233502538071067\n", "        },\n", "        {\n", "            \"year\": 2020,\n", "            \"turnover\": 13978500000.0,\n", "            \"FCF\": 3665600000.0,\n", "            \"ROCE_using_FCF\": 0.1773914895058532,\n", "            \"shares\": 419100000.0,\n", "            \"FCF_margin\": 0.26223128375719856\n", "        },\n", "        {\n", "            \"year\": 2021,\n", "            \"turnover\": 18611000000.0,\n", "            \"FCF\": 9945100000.0,\n", "            \"ROCE_using_FCF\": 0.5545697875425194,\n", "            \"shares\": 410400000.0,\n", "            \"FCF_margin\": 0.5343667723389394\n", "        },\n", "        {\n", "            \"year\": 2022,\n", "            \"turnover\": 21173400000.0,\n", "            \"FCF\": 7204999999.0,\n", "            \"ROCE_using_FCF\": 0.342062534965865,\n", "            \"shares\": 398000000.0,\n", "            \"FCF_margin\": 0.34028545245449476\n", "        },\n", "        {\n", "            \"year\": 2023,\n", "            \"turnover\": 27558500000.0,\n", "            \"FCF\": 3247200000.0,\n", "            \"ROCE_using_FCF\": 0.1371121657912071,\n", "            \"shares\": 394100000.0,\n", "            \"FCF_margin\": 0.11782934484823195\n", "        },\n", "        {\n", "            \"year\": 2024,\n", "            \"turnover\": 28262900000.0,\n", "            \"FCF\": 9099000000.0,\n", "            \"ROCE_using_FCF\": 0.31883580604242734,\n", "            \"shares\": 393600000.0,\n", "            \"FCF_margin\": 0.3219414851271455\n", "        }\n", "    ],\n", "    \"latest_price\": 867.3,\n", "    \"ttm_per\": 35.778243691052765,\n", "    \"latest_per\": 36.7702178753875,\n", "    \"average_per\": 43.933407181481606,\n", "    \"average_pe_5y\": 43.933407181481606,\n", "    \"average_pe_10y\": 37.62730820793053,\n", "    \"ttm_pfcf\": 36.48546145764511,\n", "    \"average_pfcf_5y\": 46.96457650455025,\n", "    \"average_pfcf_10y\": 40.93200109320601,\n", "    \"latest_quarterly_eps\": 5.8967559217301755,\n", "    \"ttm_eps\": 24.24098867147271,\n", "    \"ttm_fcf_ps\": 23.7711122554068,\n", "    \"fiscal_date_ending\": \"2025-06-30\",\n", "    \"dcf_inputs\": {\n", "        \"fcf_ps\": 23.7711122554068,\n", "        \"cash\": 12735900000.0,\n", "        \"debt\": null,\n", "        \"shares\": 393600000.0\n", "    },\n", "    \"analysis_date\": \"2025-09-17\",\n", "    \"symbol\": \"ASML\"\n", "}\n"]}], "source": ["metrics_dict = analyze_stock(ticker, API_KEY, num_periods=5)\n", "\n", "# Ensure the analysis directory exists\n", "os.makedirs('analysis', exist_ok=True)\n", "\n", "# Save the metrics_dict to a JSON file\n", "file_path = os.path.join('analysis', f'{ticker}.json')\n", "with open(file_path, 'w') as f:\n", "    json.dump(metrics_dict, f, indent=4)\n", "\n", "print(json.dumps(metrics_dict, indent=4))"]}], "metadata": {"kernelspec": {"display_name": "stock-analyzer", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.10"}}, "nbformat": 4, "nbformat_minor": 2}