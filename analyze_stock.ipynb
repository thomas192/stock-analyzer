{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"VANTAGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching and Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APIRateLimitError(Exception):\n",
    "    \"\"\"Custom exception raised when the API rate limit is exceeded.\"\"\"\n",
    "    pass\n",
    "\n",
    "def fetch_income_statement(symbol: str, api_key: str, folder: str = 'data') -> dict:\n",
    "    file_path = os.path.join(folder, f'{symbol}_income_statement.json')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    url = f'https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol={symbol}&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if \"Information\" in data and \"rate limit\" in data[\"Information\"].lower():\n",
    "        raise APIRateLimitError(data[\"Information\"])\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def fetch_balance_sheet(symbol: str, api_key: str, folder: str = 'data') -> dict:\n",
    "    file_path = os.path.join(folder, f'{symbol}_balance_sheet.json')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    url = f'https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol={symbol}&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if \"Information\" in data and \"rate limit\" in data[\"Information\"].lower():\n",
    "        raise APIRateLimitError(data[\"Information\"])\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def fetch_cash_flow(symbol: str, api_key: str, folder: str = 'data') -> dict:\n",
    "    file_path = os.path.join(folder, f'{symbol}_cash_flow.json')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    url = f'https://www.alphavantage.co/query?function=CASH_FLOW&symbol={symbol}&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if \"Information\" in data and \"rate limit\" in data[\"Information\"].lower():\n",
    "        raise APIRateLimitError(data[\"Information\"])\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_columns_to_numeric(df):\n",
    "    \"\"\"\n",
    "    Convert necessary columns to numeric within a DataFrame.\n",
    "    \"\"\"\n",
    "    numeric_cols = [\n",
    "        'netIncome', 'totalRevenue', 'operatingCashflow', 'capitalExpenditures',\n",
    "        'cashAndCashEquivalentsAtCarryingValue', 'totalAssets',\n",
    "        'totalCurrentLiabilities', 'currentDebt', 'cashAndShortTermInvestments',\n",
    "        'longTermDebt', 'commonStockSharesOutstanding'\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "def merge_reports_df(income_statement: dict,\n",
    "                     balance_sheet: dict,\n",
    "                     cash_flow: dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Merge annual and quarterly reports from three API responses into two DataFrames.\n",
    "    Return a dict with 'symbol', 'annual' DataFrame, and 'quarterly' DataFrame.\n",
    "    \"\"\"\n",
    "    # --- Annual Reports ---\n",
    "    annual_income = pd.DataFrame(income_statement.get('annualReports', []))\n",
    "    annual_balance = pd.DataFrame(balance_sheet.get('annualReports', []))\n",
    "    annual_cash = pd.DataFrame(cash_flow.get('annualReports', []))\n",
    "\n",
    "    # Drop unwanted columns to avoid collisions in merges\n",
    "    annual_balance.drop(columns=['reportedCurrency'], errors='ignore', inplace=True)\n",
    "    annual_cash.drop(columns=['reportedCurrency', 'netIncome'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Convert 'fiscalDateEnding' to datetime and sort\n",
    "    for df in (annual_income, annual_balance, annual_cash):\n",
    "        if 'fiscalDateEnding' in df.columns:\n",
    "            df['fiscalDateEnding'] = pd.to_datetime(df['fiscalDateEnding'])\n",
    "            df.sort_values('fiscalDateEnding', inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Merge annual data\n",
    "    annual_df = pd.merge(annual_income, annual_balance, on='fiscalDateEnding', how='outer')\n",
    "    annual_df = pd.merge(annual_df, annual_cash, on='fiscalDateEnding', how='outer')\n",
    "    convert_columns_to_numeric(annual_df)\n",
    "\n",
    "    # --- Quarterly Reports ---\n",
    "    quarterly_income = pd.DataFrame(income_statement.get('quarterlyReports', []))\n",
    "    quarterly_balance = pd.DataFrame(balance_sheet.get('quarterlyReports', []))\n",
    "    quarterly_cash = pd.DataFrame(cash_flow.get('quarterlyReports', []))\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    quarterly_balance.drop(columns=['reportedCurrency'], errors='ignore', inplace=True)\n",
    "    quarterly_cash.drop(columns=['reportedCurrency', 'netIncome'], errors='ignore', inplace=True)\n",
    "\n",
    "    for df in (quarterly_income, quarterly_balance, quarterly_cash):\n",
    "        if 'fiscalDateEnding' in df.columns:\n",
    "            df['fiscalDateEnding'] = pd.to_datetime(df['fiscalDateEnding'])\n",
    "            df.sort_values('fiscalDateEnding', inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Merge quarterly data\n",
    "    quarterly_df = pd.merge(quarterly_income, quarterly_balance, on='fiscalDateEnding', how='outer')\n",
    "    quarterly_df = pd.merge(quarterly_df, quarterly_cash, on='fiscalDateEnding', how='outer')\n",
    "    convert_columns_to_numeric(quarterly_df)\n",
    "\n",
    "    return {\n",
    "        'symbol': income_statement.get('symbol', 'N/A'),\n",
    "        'annual': annual_df,\n",
    "        'quarterly': quarterly_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_close_prices(ticker_symbol: str,\n",
    "                            start_year: int,\n",
    "                            end_year: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve and return a DataFrame with columns:\n",
    "        'year' and 'close' (the last close price of that year).\n",
    "    \"\"\"\n",
    "    start_date = f\"{start_year}-01-01\"\n",
    "    end_date = f\"{end_year}-12-31\"\n",
    "\n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "    hist = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "    if hist.empty:\n",
    "        return pd.DataFrame(columns=['year', 'close'])\n",
    "\n",
    "    if not isinstance(hist.index, pd.DatetimeIndex):\n",
    "        hist.index = pd.to_datetime(hist.index)\n",
    "\n",
    "    # Resample to get the last closing price of each year\n",
    "    yearly = hist['Close'].resample('YE').last().dropna()\n",
    "\n",
    "    # Convert to a DataFrame with columns: year, close\n",
    "    df_price = yearly.reset_index()\n",
    "    df_price['year'] = df_price['Date'].dt.year\n",
    "    df_price.rename(columns={'Close': 'close'}, inplace=True)\n",
    "    return df_price[['year', 'close']]\n",
    "\n",
    "\n",
    "def get_latest_price(ticker_symbol: str) -> float:\n",
    "    \"\"\"\n",
    "    Get the latest market price (attempt from 'regularMarketPrice'\n",
    "    or fallback to 'previousClose').\n",
    "    \"\"\"\n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "    latest_price = ticker.info.get('previousClose')\n",
    "    return float(latest_price) if latest_price else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataframes(symbol: str,\n",
    "                       annual_df: pd.DataFrame,\n",
    "                       quarterly_df: pd.DataFrame,\n",
    "                       num_periods: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform all the computations on annual_df and quarterly_df in a vectorized manner,\n",
    "    then return a dictionary with the final metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 1. Prepare the DataFrames\n",
    "    # ----------------------------------------\n",
    "    # For annual: create columns for FCF, yoy growth\n",
    "    annual_df['fcf'] = annual_df['operatingCashflow'] - annual_df['capitalExpenditures']\n",
    "    annual_df['year'] = annual_df['fiscalDateEnding'].dt.year\n",
    "\n",
    "    # For TTM calculations in quarterly_df, use rolling(4) sums\n",
    "    quarterly_df['fcf'] = quarterly_df['operatingCashflow'] - quarterly_df['capitalExpenditures']\n",
    "    quarterly_df['ttm_fcf'] = quarterly_df['fcf'].rolling(4).sum()\n",
    "    quarterly_df['ttm_net_income'] = quarterly_df['netIncome'].rolling(4).sum()\n",
    "\n",
    "    # We also want the shares from the latest quarter (assuming it doesn't drastically change).\n",
    "    # We'll just take the 'commonStockSharesOutstanding' from the latest quarter for TTM calcs.\n",
    "    # For TTM EPS or TTM FCF/share, we assume the most recent share count is a decent approximation.\n",
    "    quarterly_df['shares'] = quarterly_df['commonStockSharesOutstanding'].ffill()\n",
    "\n",
    "    # TTM EPS = ttm_net_income / shares\n",
    "    quarterly_df['ttm_eps'] = quarterly_df.apply(\n",
    "        lambda row: row['ttm_net_income'] / row['shares']\n",
    "        if pd.notnull(row['ttm_net_income']) and pd.notnull(row['shares']) and row['shares'] != 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # TTM FCF per share = ttm_fcf / shares\n",
    "    quarterly_df['ttm_fcf_ps'] = quarterly_df.apply(\n",
    "        lambda row: row['ttm_fcf'] / row['shares']\n",
    "        if pd.notnull(row['ttm_fcf']) and pd.notnull(row['shares']) and row['shares'] != 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Latest row in quarterly_df (most recent quarter)\n",
    "    latest_q = quarterly_df.iloc[-1] if not quarterly_df.empty else None\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 2. Basic Valuation Metrics (TTM, Latest EPS)\n",
    "    # ----------------------------------------\n",
    "    latest_quarter_eps = None\n",
    "    ttm_eps = None\n",
    "    ttm_fcf_ps = None\n",
    "    fiscal_date_ending = None\n",
    "\n",
    "    if latest_q is not None:\n",
    "        net_income_latest = latest_q['netIncome']\n",
    "        shares_latest = latest_q['commonStockSharesOutstanding']\n",
    "        # EPS for that single quarter\n",
    "        if pd.notnull(net_income_latest) and pd.notnull(shares_latest) and shares_latest != 0:\n",
    "            latest_quarter_eps = net_income_latest / shares_latest\n",
    "        # TTM\n",
    "        ttm_eps = latest_q['ttm_eps']\n",
    "        ttm_fcf_ps = latest_q['ttm_fcf_ps']\n",
    "        if pd.notnull(latest_q['fiscalDateEnding']):\n",
    "            fiscal_date_ending = latest_q['fiscalDateEnding'].strftime('%Y-%m-%d')\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 3. Annual Growth Metrics\n",
    "    # ----------------------------------------\n",
    "    # We'll select the last (num_periods + 1) to compute average yoy growth\n",
    "    # Because yoy growth uses shift(1).\n",
    "    df_for_growth = annual_df.copy()\n",
    "    df_for_growth['revenue_growth'] = df_for_growth['totalRevenue'].pct_change()\n",
    "    df_for_growth['fcf_growth'] = df_for_growth['fcf'].pct_change()\n",
    "    df_for_growth['shares_growth'] = df_for_growth['commonStockSharesOutstanding'].pct_change()\n",
    "\n",
    "    # For ROCE using FCF, we define capital employed = totalAssets - totalCurrentLiabilities\n",
    "    df_for_growth['capital_employed'] = df_for_growth['totalAssets'] - df_for_growth['totalCurrentLiabilities']\n",
    "    df_for_growth['roce_fcf'] = df_for_growth.apply(\n",
    "        lambda row: row['fcf'] / row['capital_employed']\n",
    "        if pd.notnull(row['fcf']) and pd.notnull(row['capital_employed']) and row['capital_employed'] != 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # net debt = (currentDebt + longTermDebt) - cash\n",
    "    # We unify 'cash' column first (prefer `cashAndShortTermInvestments`).\n",
    "    df_for_growth['cash'] = df_for_growth.get('cashAndShortTermInvestments', 0).fillna(0)\n",
    "    # If there's also `cashAndCashEquivalentsAtCarryingValue` we can combine or fill\n",
    "    if 'cashAndCashEquivalentsAtCarryingValue' in df_for_growth.columns:\n",
    "        df_for_growth['cash'] = df_for_growth['cash'].where(\n",
    "            df_for_growth['cash'] != 0,\n",
    "            df_for_growth['cashAndCashEquivalentsAtCarryingValue']\n",
    "        )\n",
    "\n",
    "    df_for_growth['debt'] = df_for_growth['currentDebt'] + df_for_growth['longTermDebt']\n",
    "    df_for_growth['net_debt'] = df_for_growth['debt'] - df_for_growth['cash']\n",
    "    df_for_growth['net_debt_to_fcf'] = df_for_growth.apply(\n",
    "        lambda row: row['net_debt'] / row['fcf']\n",
    "        if pd.notnull(row['net_debt']) and pd.notnull(row['fcf']) and row['fcf'] != 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # FCF margin\n",
    "    df_for_growth['fcf_margin'] = df_for_growth.apply(\n",
    "        lambda row: row['fcf'] / row['totalRevenue']\n",
    "        if pd.notnull(row['fcf']) and pd.notnull(row['totalRevenue']) and row['totalRevenue'] != 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Select the last num_periods for averaging\n",
    "    recent_subset = df_for_growth.tail(num_periods)\n",
    "\n",
    "    avg_turnover_growth = recent_subset['revenue_growth'].mean() if not recent_subset.empty else None\n",
    "    avg_fcf_growth = recent_subset['fcf_growth'].mean() if not recent_subset.empty else None\n",
    "    avg_stock_increase = recent_subset['shares_growth'].mean() if not recent_subset.empty else None\n",
    "    avg_roce_fcf = recent_subset['roce_fcf'].mean() if not recent_subset.empty else None\n",
    "    latest_net_debt_to_fcf = df_for_growth['net_debt_to_fcf'].iloc[-1] if not df_for_growth.empty else None\n",
    "    avg_fcf_margin = recent_subset['fcf_margin'].mean() if not recent_subset.empty else None\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 4. Price Data & Ratios (Annual)\n",
    "    # ----------------------------------------\n",
    "    # We get up to 10 years of data to cover the user's range\n",
    "    end_year = datetime.today().year - 1  # last complete year\n",
    "    start_year = end_year - 10\n",
    "    df_price = get_yearly_close_prices(symbol, start_year, end_year)\n",
    "\n",
    "    # Merge annual data with price data on 'year'\n",
    "    annual_price_df = pd.merge(annual_df, df_price, on='year', how='left')\n",
    "\n",
    "    # Compute annual EPS\n",
    "    annual_price_df['eps'] = annual_price_df.apply(\n",
    "        lambda row: row['netIncome'] / row['commonStockSharesOutstanding']\n",
    "        if pd.notnull(row['netIncome']) and pd.notnull(row['commonStockSharesOutstanding']) and row['commonStockSharesOutstanding'] != 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Price / EPS\n",
    "    annual_price_df['p_e'] = annual_price_df.apply(\n",
    "        lambda row: row['close'] / row['eps']\n",
    "        if pd.notnull(row['close']) and pd.notnull(row['eps']) and row['eps'] > 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # FCF per share\n",
    "    annual_price_df['fcf_per_share'] = annual_price_df.apply(\n",
    "        lambda row: row['fcf'] / row['commonStockSharesOutstanding']\n",
    "        if pd.notnull(row['fcf']) and pd.notnull(row['commonStockSharesOutstanding']) and row['commonStockSharesOutstanding'] != 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Price / FCF\n",
    "    annual_price_df['p_fcf'] = annual_price_df.apply(\n",
    "        lambda row: row['close'] / row['fcf_per_share']\n",
    "        if pd.notnull(row['close']) and pd.notnull(row['fcf_per_share']) and row['fcf_per_share'] > 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Filter to non-null p_e / p_fcf\n",
    "    valid_pe = annual_price_df.dropna(subset=['p_e'])\n",
    "    valid_pfcf = annual_price_df.dropna(subset=['p_fcf'])\n",
    "\n",
    "    # Compute average P/E and P/FCF over last 5/10 years (or whatever is possible)\n",
    "    pe_values = valid_pe['p_e'].values\n",
    "    pfcf_values = valid_pfcf['p_fcf'].values\n",
    "\n",
    "    average_pe_5y = None\n",
    "    average_pe_10y = None\n",
    "    if len(pe_values) >= 5:\n",
    "        average_pe_5y = pe_values[-5:].mean()\n",
    "    if len(pe_values) >= 10:\n",
    "        average_pe_10y = pe_values[-10:].mean()\n",
    "\n",
    "    average_pfcf_5y = None\n",
    "    average_pfcf_10y = None\n",
    "    if len(pfcf_values) >= 5:\n",
    "        average_pfcf_5y = pfcf_values[-5:].mean()\n",
    "    if len(pfcf_values) >= 10:\n",
    "        average_pfcf_10y = pfcf_values[-10:].mean()\n",
    "\n",
    "    # We'll also compute an average P/E for the last num_periods specifically\n",
    "    # (this is the \"average_per\" in your old code).\n",
    "    last_n_pe = valid_pe.tail(num_periods)['p_e']\n",
    "    average_per = last_n_pe.mean() if not last_n_pe.empty else None\n",
    "\n",
    "    # Now get latest price from Yahoo\n",
    "    latest_price = get_latest_price(symbol)\n",
    "\n",
    "    # TTM PER (latest price / TTM EPS)\n",
    "    ttm_per = None\n",
    "    if latest_price and ttm_eps and ttm_eps > 0:\n",
    "        ttm_per = latest_price / ttm_eps\n",
    "\n",
    "    # Latest PER (annualized from last quarter's EPS * 4)\n",
    "    latest_per = None\n",
    "    if latest_price and latest_quarter_eps and (latest_quarter_eps * 4) > 0:\n",
    "        latest_per = latest_price / (latest_quarter_eps * 4)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 5. DCF Inputs from the latest annual row\n",
    "    # ----------------------------------------\n",
    "    latest_annual = annual_df.iloc[-1] if not annual_df.empty else None\n",
    "\n",
    "    dcf_inputs = {}\n",
    "    if latest_annual is not None:\n",
    "        # Combine possible cash columns\n",
    "        cash_val = latest_annual.get('cashAndShortTermInvestments', 0)\n",
    "        if not cash_val:\n",
    "            cash_val = latest_annual.get('cashAndCashEquivalentsAtCarryingValue', 0)\n",
    "\n",
    "        current_debt = latest_annual.get('currentDebt') or 0\n",
    "        long_term_debt = latest_annual.get('longTermDebt') or 0\n",
    "        debt_total = current_debt + long_term_debt\n",
    "\n",
    "        shares = latest_annual.get('commonStockSharesOutstanding') or 0\n",
    "\n",
    "        dcf_inputs = {\n",
    "            'fcf_ps': float(ttm_fcf_ps),\n",
    "            'cash': float(cash_val) if cash_val else None,\n",
    "            'debt': float(debt_total),\n",
    "            'shares': float(shares),\n",
    "        }\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 6. Compile Results into Dictionary\n",
    "    # ----------------------------------------\n",
    "    results = {\n",
    "        # Growth & Profitability\n",
    "        'avg_turnover_growth': avg_turnover_growth,\n",
    "        'avg_FCF_growth': avg_fcf_growth,\n",
    "        'avg_ROCE_using_FCF': avg_roce_fcf,\n",
    "        'latest_net_debt_to_FCF': latest_net_debt_to_fcf,\n",
    "        'avg_stock_increase': avg_stock_increase,\n",
    "        'avg_FCF_margin': avg_fcf_margin,\n",
    "\n",
    "        # Valuation (P/E, P/FCF)\n",
    "        'latest_price': latest_price,\n",
    "        'ttm_per': ttm_per,\n",
    "        'latest_per': latest_per,\n",
    "        'average_per': average_per,\n",
    "\n",
    "        'average_pe_5y': average_pe_5y,\n",
    "        'average_pe_10y': average_pe_10y,\n",
    "        'average_pfcf_5y': average_pfcf_5y,\n",
    "        'average_pfcf_10y': average_pfcf_10y,\n",
    "\n",
    "        # TTM / Quarter-based metrics\n",
    "        'latest_quarterly_eps': latest_quarter_eps,\n",
    "        'ttm_eps': ttm_eps,\n",
    "        'ttm_fcf_ps': ttm_fcf_ps,\n",
    "        'fiscal_date_ending': fiscal_date_ending,\n",
    "\n",
    "        # DCF Inputs\n",
    "        'dcf_inputs': dcf_inputs,\n",
    "\n",
    "        # Additional metadata\n",
    "        'analysis_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "        'symbol': symbol\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_stock(ticker: str, api_key: str, num_periods: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch raw data, merge, run the all-in-DataFrame analysis, and return\n",
    "    a dictionary of results (no printing or saving).\n",
    "    \"\"\"\n",
    "    # Fetch data\n",
    "    income_statement = fetch_income_statement(ticker, api_key)\n",
    "    balance_sheet_data = fetch_balance_sheet(ticker, api_key)\n",
    "    cash_flow_data = fetch_cash_flow(ticker, api_key)\n",
    "\n",
    "    # Merge into DataFrames\n",
    "    merged_data = merge_reports_df(income_statement, balance_sheet_data, cash_flow_data)\n",
    "    annual_df = merged_data['annual']\n",
    "    quarterly_df = merged_data['quarterly']\n",
    "    symbol = merged_data.get('symbol', ticker)\n",
    "\n",
    "    # Perform the big analysis\n",
    "    results = analyze_dataframes(symbol, annual_df, quarterly_df, num_periods=num_periods)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ticker = 'AMZN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              NaN\n",
      "1     2.920000e+09\n",
      "2     2.516000e+09\n",
      "3     2.092000e+09\n",
      "4     3.950000e+08\n",
      "5     2.031000e+09\n",
      "6     1.949000e+09\n",
      "7     7.450000e+09\n",
      "8     9.399000e+09\n",
      "9     6.410000e+09\n",
      "10    1.729600e+10\n",
      "11    2.165300e+10\n",
      "12    2.592400e+10\n",
      "13   -1.472600e+10\n",
      "14   -1.689300e+10\n",
      "15    3.221700e+10\n",
      "Name: fcf, dtype: float64\n",
      "0    2008-12-31\n",
      "1    2009-12-31\n",
      "2    2010-12-31\n",
      "3    2011-12-31\n",
      "4    2012-12-31\n",
      "5    2013-12-31\n",
      "6    2014-12-31\n",
      "7    2015-12-31\n",
      "8    2016-12-31\n",
      "9    2017-12-31\n",
      "10   2018-12-31\n",
      "11   2019-12-31\n",
      "12   2020-12-31\n",
      "13   2021-12-31\n",
      "14   2022-12-31\n",
      "15   2023-12-31\n",
      "Name: fiscalDateEnding, dtype: datetime64[ns]\n",
      "{\n",
      "    \"avg_turnover_growth\": 0.2024668391876207,\n",
      "    \"avg_FCF_growth\": -0.7757712410135389,\n",
      "    \"avg_ROCE_using_FCF\": 0.05429950098660301,\n",
      "    \"latest_net_debt_to_FCF\": -0.2815904646615141,\n",
      "    \"avg_stock_increase\": 3.834359903448617,\n",
      "    \"avg_FCF_margin\": 0.027382854427784643,\n",
      "    \"latest_price\": 242.06,\n",
      "    \"ttm_per\": 51.020547445255474,\n",
      "    \"latest_per\": 41.497466401356995,\n",
      "    \"average_per\": 13.173307189115793,\n",
      "    \"average_pe_5y\": 13.173307189115793,\n",
      "    \"average_pe_10y\": null,\n",
      "    \"average_pfcf_5y\": 12.159881119936456,\n",
      "    \"average_pfcf_10y\": null,\n",
      "    \"latest_quarterly_eps\": 1.4582818000190276,\n",
      "    \"ttm_eps\": 4.744363048235182,\n",
      "    \"ttm_fcf_ps\": 4.086480829607078,\n",
      "    \"fiscal_date_ending\": \"2024-09-30\",\n",
      "    \"dcf_inputs\": {\n",
      "        \"initial_fcf\": 32217000000.0,\n",
      "        \"cash\": 86780000000.0,\n",
      "        \"debt\": 77708000000.0,\n",
      "        \"shares\": 10383000000.0\n",
      "    },\n",
      "    \"analysis_date\": \"2025-02-06\",\n",
      "    \"symbol\": \"AMZN\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = analyze_stock(ticker, API_KEY, num_periods=5)\n",
    "\n",
    "# Ensure the analysis directory exists\n",
    "os.makedirs('analysis', exist_ok=True)\n",
    "\n",
    "# Save the metrics_dict to a JSON file\n",
    "file_path = os.path.join('analysis', f'{ticker}.json')\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(metrics_dict, f, indent=4)\n",
    "\n",
    "print(json.dumps(metrics_dict, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
