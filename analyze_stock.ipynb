{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"VANTAGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching and Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APIRateLimitError(Exception):\n",
    "    \"\"\"Custom exception raised when the API rate limit is exceeded.\"\"\"\n",
    "    pass\n",
    "\n",
    "def fetch_income_statement(symbol: str, api_key: str, folder: str = 'data') -> dict:\n",
    "    file_path = os.path.join(folder, f'{symbol}_income_statement.json')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    url = f'https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol={symbol}&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if \"Information\" in data and \"rate limit\" in data[\"Information\"].lower():\n",
    "        raise APIRateLimitError(data[\"Information\"])\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def fetch_balance_sheet(symbol: str, api_key: str, folder: str = 'data') -> dict:\n",
    "    file_path = os.path.join(folder, f'{symbol}_balance_sheet.json')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    url = f'https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol={symbol}&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if \"Information\" in data and \"rate limit\" in data[\"Information\"].lower():\n",
    "        raise APIRateLimitError(data[\"Information\"])\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def fetch_cash_flow(symbol: str, api_key: str, folder: str = 'data') -> dict:\n",
    "    file_path = os.path.join(folder, f'{symbol}_cash_flow.json')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    url = f'https://www.alphavantage.co/query?function=CASH_FLOW&symbol={symbol}&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if \"Information\" in data and \"rate limit\" in data[\"Information\"].lower():\n",
    "        raise APIRateLimitError(data[\"Information\"])\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_reports_df(income_statement: dict, balance_sheet: dict, cash_flow: dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Merge the annual and quarterly reports from the three API responses into pandas DataFrames,\n",
    "    merging on the 'fiscalDateEnding' column.\n",
    "    \"\"\"\n",
    "    # --- Annual Reports ---\n",
    "    annual_income = pd.DataFrame(income_statement.get('annualReports', []))\n",
    "    annual_balance = pd.DataFrame(balance_sheet.get('annualReports', []))\n",
    "    annual_cash = pd.DataFrame(cash_flow.get('annualReports', []))\n",
    "\n",
    "    # Drop unwanted duplicate keys\n",
    "    annual_balance.drop(columns=['reportedCurrency'], errors='ignore', inplace=True)\n",
    "    annual_cash.drop(columns=['reportedCurrency', 'netIncome'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Convert fiscalDateEnding to datetime and sort\n",
    "    for df in (annual_income, annual_balance, annual_cash):\n",
    "        if 'fiscalDateEnding' in df.columns:\n",
    "            df['fiscalDateEnding'] = pd.to_datetime(df['fiscalDateEnding'])\n",
    "            df.sort_values('fiscalDateEnding', inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Merge the three annual DataFrames on 'fiscalDateEnding'\n",
    "    annual_df = pd.merge(annual_income, annual_balance, on='fiscalDateEnding', how='outer')\n",
    "    annual_df = pd.merge(annual_df, annual_cash, on='fiscalDateEnding', how='outer')\n",
    "\n",
    "    # --- Quarterly Reports ---\n",
    "    quarterly_income = pd.DataFrame(income_statement.get('quarterlyReports', []))\n",
    "    quarterly_balance = pd.DataFrame(balance_sheet.get('quarterlyReports', []))\n",
    "    quarterly_cash = pd.DataFrame(cash_flow.get('quarterlyReports', []))\n",
    "\n",
    "    # Drop unwanted duplicate keys\n",
    "    quarterly_balance.drop(columns=['reportedCurrency'], errors='ignore', inplace=True)\n",
    "    quarterly_cash.drop(columns=['reportedCurrency', 'netIncome'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Convert fiscalDateEnding to datetime and sort\n",
    "    for df in (quarterly_income, quarterly_balance, quarterly_cash):\n",
    "        if 'fiscalDateEnding' in df.columns:\n",
    "            df['fiscalDateEnding'] = pd.to_datetime(df['fiscalDateEnding'])\n",
    "            df.sort_values('fiscalDateEnding', inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Merge the three quarterly DataFrames on 'fiscalDateEnding'\n",
    "    quarterly_df = pd.merge(quarterly_income, quarterly_balance, on='fiscalDateEnding', how='outer')\n",
    "    quarterly_df = pd.merge(quarterly_df, quarterly_cash, on='fiscalDateEnding', how='outer')\n",
    "\n",
    "    return {\n",
    "        'symbol': income_statement.get('symbol', 'N/A'),\n",
    "        'annual': annual_df,\n",
    "        'quarterly': quarterly_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPS Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eps_metrics(quarterly_df: pd.DataFrame, annual_df: pd.DataFrame, num_period: int) -> dict:\n",
    "    \"\"\"\n",
    "    Compute EPS metrics using quarterly and annual DataFrames.\n",
    "      - latest_quarterly_eps: EPS from the most recent quarterly report.\n",
    "      - ttm_eps: Trailing Twelve Months EPS.\n",
    "      - annual_eps: Dictionary mapping fiscal year to annual EPS.\n",
    "    \"\"\"\n",
    "    # Ensure necessary columns are numeric\n",
    "    for col in ['netIncome', 'commonStockSharesOutstanding']:\n",
    "        if col in quarterly_df.columns:\n",
    "            quarterly_df[col] = pd.to_numeric(quarterly_df[col], errors='coerce')\n",
    "        if col in annual_df.columns:\n",
    "            annual_df[col] = pd.to_numeric(annual_df[col], errors='coerce')\n",
    "\n",
    "    latest_quarter = quarterly_df.iloc[-1]\n",
    "    net_income_latest = latest_quarter.get('netIncome')\n",
    "    shares_latest = latest_quarter.get('commonStockSharesOutstanding')\n",
    "\n",
    "    if pd.notnull(net_income_latest) and pd.notnull(shares_latest) and shares_latest != 0:\n",
    "        latest_eps = net_income_latest / shares_latest\n",
    "    else:\n",
    "        latest_eps = None\n",
    "    \n",
    "    # Compute TTM EPS (using the last 4 quarters)\n",
    "    if len(quarterly_df) >= 4:\n",
    "        last_four = quarterly_df.iloc[-4:]\n",
    "        if last_four['netIncome'].isnull().any():\n",
    "            ttm_eps = None\n",
    "        else:\n",
    "            total_net_income = last_four['netIncome'].sum()\n",
    "            ttm_eps = total_net_income / shares_latest if pd.notnull(shares_latest) and shares_latest != 0 else None\n",
    "    else:\n",
    "        ttm_eps = None\n",
    "\n",
    "    # Compute EPS for each annual report\n",
    "    annual_df['eps'] = annual_df.apply(\n",
    "        lambda row: row['netIncome'] / row['commonStockSharesOutstanding']\n",
    "        if pd.notnull(row['netIncome']) and pd.notnull(row['commonStockSharesOutstanding']) and row['commonStockSharesOutstanding'] != 0\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "    annual_df['year'] = annual_df['fiscalDateEnding'].dt.year\n",
    "    selected_annual = annual_df.iloc[-num_period:]\n",
    "    annual_eps = {row['year']: row['eps'] for _, row in selected_annual.iterrows()}\n",
    "    \n",
    "    return {\n",
    "        'latest_quarterly_eps': latest_eps,\n",
    "        'ttm_eps': ttm_eps,\n",
    "        'fiscal_date_ending': latest_quarter['fiscalDateEnding'].strftime('%Y-%m-%d') if pd.notnull(latest_quarter['fiscalDateEnding']) else None,\n",
    "        'annual_eps': annual_eps\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_financial_metrics(annual_df: pd.DataFrame, num_periods: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Compute various financial metrics from the annual data using DataFrame operations:\n",
    "      - Average turnover (revenue) growth.\n",
    "      - Average FCF growth.\n",
    "      - Average ROCE using FCF.\n",
    "      - Latest net debt/FCF ratio.\n",
    "      - Average stock number increase.\n",
    "      - Average FCF margin.\n",
    "    \"\"\"\n",
    "    # Convert necessary columns to numeric\n",
    "    numeric_cols = ['totalRevenue', 'operatingCashflow', 'capitalExpenditures',\n",
    "                    'totalAssets', 'totalCurrentLiabilities', 'currentDebt',\n",
    "                    'longTermDebt', 'commonStockSharesOutstanding']\n",
    "    for col in numeric_cols:\n",
    "        if col in annual_df.columns:\n",
    "            annual_df[col] = pd.to_numeric(annual_df[col], errors='coerce')\n",
    "    \n",
    "    # For cash, try one field then the other\n",
    "    if 'cashAndShortTermInvestments' in annual_df.columns:\n",
    "        annual_df['cash'] = pd.to_numeric(annual_df['cashAndShortTermInvestments'], errors='coerce')\n",
    "    if 'cashAndCashEquivalentsAtCarryingValue' in annual_df.columns:\n",
    "        annual_df['cash'] = annual_df.get('cash', pd.Series([None]*len(annual_df))).fillna(\n",
    "            pd.to_numeric(annual_df['cashAndCashEquivalentsAtCarryingValue'], errors='coerce')\n",
    "        )\n",
    "    \n",
    "    annual_df = annual_df.sort_values('fiscalDateEnding').reset_index(drop=True)\n",
    "    total_periods = len(annual_df)\n",
    "    non_growth_df = annual_df.iloc[-num_periods:].copy() if total_periods >= num_periods else annual_df.copy()\n",
    "    growth_df = annual_df.iloc[-(num_periods + 1):].copy() if total_periods >= (num_periods + 1) else annual_df.copy()\n",
    "    \n",
    "    # Create Free Cash Flow (FCF) column\n",
    "    for df in (non_growth_df, growth_df):\n",
    "        df['fcf'] = df['operatingCashflow'] - df['capitalExpenditures']\n",
    "    \n",
    "    # Compute growth metrics (using percentage change)\n",
    "    avg_turnover_growth = growth_df['totalRevenue'].pct_change().mean() if len(growth_df) > 1 else None\n",
    "    avg_FCF_growth = growth_df['fcf'].pct_change().mean() if len(growth_df) > 1 else None\n",
    "    avg_stock_increase = growth_df['commonStockSharesOutstanding'].pct_change().mean() if len(growth_df) > 1 else None\n",
    "\n",
    "    # Compute ROCE using FCF = FCF / (totalAssets - totalCurrentLiabilities)\n",
    "    non_growth_df['capital_employed'] = non_growth_df['totalAssets'] - non_growth_df['totalCurrentLiabilities']\n",
    "    non_growth_df['roce'] = non_growth_df.apply(\n",
    "        lambda row: row['fcf'] / row['capital_employed'] if pd.notnull(row['fcf']) and pd.notnull(row['capital_employed']) and row['capital_employed'] != 0 else None,\n",
    "        axis=1\n",
    "    )\n",
    "    avg_roce_fcf = non_growth_df['roce'].dropna().mean() if not non_growth_df['roce'].dropna().empty else None\n",
    "\n",
    "    # Compute net debt: (currentDebt + longTermDebt) - cash\n",
    "    non_growth_df['debt'] = non_growth_df['currentDebt'] + non_growth_df['longTermDebt']\n",
    "    non_growth_df['net_debt'] = non_growth_df.apply(\n",
    "        lambda row: row['debt'] - row['cash'] if pd.notnull(row['debt']) and pd.notnull(row['cash']) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    non_growth_df['net_debt_to_FCF'] = non_growth_df.apply(\n",
    "        lambda row: row['net_debt'] / row['fcf'] if pd.notnull(row['net_debt']) and pd.notnull(row['fcf']) and row['fcf'] != 0 else None,\n",
    "        axis=1\n",
    "    )\n",
    "    latest_net_debt_to_FCF = non_growth_df['net_debt_to_FCF'].iloc[-1] if not non_growth_df['net_debt_to_FCF'].empty else None\n",
    "\n",
    "    # Compute FCF margin = FCF / totalRevenue\n",
    "    non_growth_df['fcf_margin'] = non_growth_df.apply(\n",
    "        lambda row: row['fcf'] / row['totalRevenue'] if pd.notnull(row['fcf']) and pd.notnull(row['totalRevenue']) and row['totalRevenue'] != 0 else None,\n",
    "        axis=1\n",
    "    )\n",
    "    avg_FCF_margin = non_growth_df['fcf_margin'].dropna().mean() if not non_growth_df['fcf_margin'].dropna().empty else None\n",
    "\n",
    "    return {\n",
    "        'avg_turnover_growth': avg_turnover_growth,\n",
    "        'avg_FCF_growth': avg_FCF_growth,\n",
    "        'avg_ROCE_using_FCF': avg_roce_fcf,\n",
    "        'latest_net_debt_to_FCF': latest_net_debt_to_FCF,\n",
    "        'avg_stock_increase': avg_stock_increase,\n",
    "        'avg_FCF_margin': avg_FCF_margin,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YFinance Price Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_close_and_latest_quote(ticker_symbol: str, num_periods: int) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve the yearly closing prices for the last num_period complete fiscal years and the latest price quote.\n",
    "    \"\"\"\n",
    "    today = datetime.today()\n",
    "    current_year = today.year\n",
    "    last_complete_year = current_year - 1\n",
    "    first_complete_year = last_complete_year - num_periods  # may include one extra year\n",
    "    start_date = f\"{first_complete_year}-01-01\"\n",
    "    end_date = f\"{last_complete_year}-12-31\"\n",
    "    \n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "    hist = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "    yearly_close = {}\n",
    "    if not hist.empty:\n",
    "        if not isinstance(hist.index, pd.DatetimeIndex):\n",
    "            hist.index = pd.to_datetime(hist.index)\n",
    "        # Resample to get the last closing price of each year\n",
    "        resampled = hist['Close'].resample('YE').last()\n",
    "        for ts, price in resampled.items():\n",
    "            year = ts.year\n",
    "            if first_complete_year <= year <= last_complete_year:\n",
    "                yearly_close[year] = price\n",
    "\n",
    "    latest_quote = ticker.info.get('regularMarketDayHigh') if ticker.info.get('regularMarketDayHigh') else ticker.info.get('previousClose')\n",
    "    return {\n",
    "        'yearly_close': yearly_close,\n",
    "        'latest_quote': latest_quote\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PER Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_ratios(ticker_symbol: str, quarterly_df: pd.DataFrame, annual_df: pd.DataFrame, num_period: int) -> dict:\n",
    "    \"\"\"\n",
    "    Compute Price-to-Earnings (PER) ratios:\n",
    "      - TTM PER: latest price / TTM EPS.\n",
    "      - Latest PER: latest price / latest quarterly EPS.\n",
    "      - Average PER: average of (yearly closing price / annual EPS) over the last num_period fiscal years.\n",
    "      - Latest price quote.\n",
    "    \"\"\"\n",
    "    eps_metrics = compute_eps_metrics(quarterly_df, annual_df, num_period)\n",
    "    price_data = get_yearly_close_and_latest_quote(ticker_symbol, num_period)\n",
    "    \n",
    "    latest_price = price_data.get('latest_quote')\n",
    "    ttm_eps = eps_metrics.get('ttm_eps')\n",
    "    latest_quarterly_eps = eps_metrics.get('latest_quarterly_eps') * 4\n",
    "    annual_eps = eps_metrics.get('annual_eps')  # dict: year -> eps\n",
    "    yearly_close = price_data.get('yearly_close')  # dict: year -> close\n",
    "    \n",
    "    ttm_per = latest_price / ttm_eps if latest_price is not None and ttm_eps is not None and ttm_eps > 0 else None\n",
    "    latest_per = latest_price / latest_quarterly_eps if latest_price is not None and latest_quarterly_eps is not None and latest_quarterly_eps > 0 else None\n",
    "    \n",
    "    per_values = []\n",
    "    for year, eps in annual_eps.items():\n",
    "        if eps is not None and eps > 0 and year in yearly_close:\n",
    "            per_values.append(yearly_close[year] / eps)\n",
    "    average_per = sum(per_values) / len(per_values) if per_values else None\n",
    "    \n",
    "    return {\n",
    "        'ttm_per': ttm_per,\n",
    "        'latest_per': latest_per,\n",
    "        'average_per': average_per,\n",
    "        'fiscal_date_ending': eps_metrics.get('fiscal_date_ending'),\n",
    "        'latest_price': latest_price\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_metrics(metrics: dict, ticker: str, num_periods: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Display the metrics in a formatted text table.\n",
    "    \"\"\"\n",
    "    def format_value(value, percentage=False):\n",
    "        if isinstance(value, (int, float)):\n",
    "            return f\"{value * 100:.2f}%\" if percentage else f\"{value:.2f}\"\n",
    "        return \"N/A\"\n",
    "    \n",
    "    output = f\"\"\"\n",
    "--------------------------------------------\n",
    "            {ticker} (last {num_periods} years)\n",
    "--------------------------------------------\n",
    "Metric                        Value\n",
    "--------------------------------------------\n",
    "Turnover Growth               {format_value(metrics.get('avg_turnover_growth'), percentage=True)}\n",
    "FCF Growth                    {format_value(metrics.get('avg_FCF_growth'), percentage=True)}\n",
    "ROCE (using FCF)              {format_value(metrics.get('avg_ROCE_using_FCF'), percentage=True)}\n",
    "Net Debt/FCF                  {format_value(metrics.get('latest_net_debt_to_FCF'))}\n",
    "Share Number Increase         {format_value(metrics.get('avg_stock_increase'), percentage=True)}\n",
    "FCF Margin                    {format_value(metrics.get('avg_FCF_margin'), percentage=True)}\n",
    "\n",
    "Average PER (5y)              {format_value(metrics.get('average_per'))}\n",
    "PER TTM                       {format_value(metrics.get('ttm_per'))}\n",
    "PER (latest quarter)          {format_value(metrics.get('latest_per'))}\n",
    "Fiscal date ending            {metrics.get('fiscal_date_ending')}\n",
    "\n",
    "Stock price                   {format_value(metrics.get('latest_price'))}\n",
    "--------------------------------------------\n",
    "\"\"\"\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Ticker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ticker = 'ASML'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fiscalDateEnding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11548\\1536241035.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'analysis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33mf'\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m.json\u001b[0m\u001b[1;33m'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0manalyze_stock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAPI_KEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11548\\1536241035.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(ticker, api_key, num_periods)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbalance_sheet_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_balance_sheet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcash_flow_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_cash_flow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Merge the reports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmerged_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_reports_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincome_statement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalance_sheet_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcash_flow_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0msymbol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'symbol'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mannual_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'annual'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mquarterly_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'quarterly'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11548\\3915632595.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(income_statement, balance_sheet, cash_flow)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fiscalDateEnding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Merge the three annual DataFrames on 'fiscalDateEnding'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mannual_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannual_income\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannual_balance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fiscalDateEnding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mannual_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannual_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannual_cash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fiscalDateEnding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# --- Quarterly Reports ---\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\agents\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\agents\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\agents\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\agents\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'fiscalDateEnding'"
     ]
    }
   ],
   "source": [
    "def analyze_stock(ticker: str, api_key: str, num_periods: int = 5) -> None:\n",
    "    # Fetch the data\n",
    "    income_statement = fetch_income_statement(ticker, api_key)\n",
    "    balance_sheet_data = fetch_balance_sheet(ticker, api_key)\n",
    "    cash_flow_data = fetch_cash_flow(ticker, api_key)\n",
    "\n",
    "    # Merge the reports\n",
    "    merged_data = merge_reports_df(income_statement, balance_sheet_data, cash_flow_data)\n",
    "    symbol = merged_data.get('symbol', ticker)\n",
    "    annual_df = merged_data['annual']\n",
    "    quarterly_df = merged_data['quarterly']\n",
    "\n",
    "    # Compute metrics\n",
    "    financial_metrics = compute_financial_metrics(annual_df, num_periods=num_periods)\n",
    "    per_ratios = compute_per_ratios(ticker, quarterly_df, annual_df, num_period=num_periods)\n",
    "\n",
    "    # Visualize the combined metrics\n",
    "    combined_metrics = {**financial_metrics, **per_ratios, **{'analysis_date': datetime.now().strftime('%Y-%m-%d')}}\n",
    "    visualize_metrics(combined_metrics, symbol, num_periods=num_periods)\n",
    "\n",
    "    # Save combined metrics to a JSON file\n",
    "    os.makedirs('analysis', exist_ok=True)\n",
    "    file_path = os.path.join('analysis', f'{ticker}.json')\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(combined_metrics, f, indent=4)\n",
    "\n",
    "analyze_stock(ticker, API_KEY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
